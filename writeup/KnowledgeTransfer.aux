\relax 
\providecommand*\new@tpo@label[2]{}
\bibstyle{biblatex}
\bibdata{KnowledgeTransfer-blx,sources}
\citation{biblatex-control}
\abx@aux@sortscheme{nty}
\abx@aux@refcontext{nty/global/}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\citation{hinton2015distilling}
\abx@aux@cite{hinton2015distilling}
\abx@aux@segm{0}{0}{hinton2015distilling}
\citation{hinton2015distilling}
\abx@aux@segm{0}{0}{hinton2015distilling}
\citation{DBLP:journals/corr/SimonyanZ14a}
\abx@aux@cite{DBLP:journals/corr/SimonyanZ14a}
\abx@aux@segm{0}{0}{DBLP:journals/corr/SimonyanZ14a}
\citation{krizhevsky2009learning}
\abx@aux@cite{krizhevsky2009learning}
\abx@aux@segm{0}{0}{krizhevsky2009learning}
\citation{DBLP:journals/corr/SimonyanZ14a}
\abx@aux@segm{0}{0}{DBLP:journals/corr/SimonyanZ14a}
\citation{krizhevsky2009learning}
\abx@aux@segm{0}{0}{krizhevsky2009learning}
\citation{hinton2015distilling}
\abx@aux@segm{0}{0}{hinton2015distilling}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}The Models}{1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Intermediate Layer Matching}{1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}The Dataset}{1}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \textbf  {Network configurations.} The convolutional layers are denoted as conv(\textit  {kernel size})-(\textit  {number of channels)} and the fully connected layers as FC-(\textit  {number of output channels}). ReLu units are omitted for brevity. The left column numbers the layers of both networks whose activations were linked in the loss functions of section X.\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:network_architectures}{{1}{2}}
\citation{*}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \textbf  {Last layer transfer results.} bla bla\relax }}{3}}
\newlabel{tab:LL_results}{{2}{3}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces \textbf  {Intermediate Layers transfer results.} used last layer with temperature 2 and $ \alpha = 10 $\relax }}{3}}
\newlabel{tab:interemediate_results}{{3}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Training Methodology}{3}}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{hinton2015distilling}{nty/global/}
\abx@aux@defaultrefcontext{0}{krizhevsky2009learning}{nty/global/}
\abx@aux@defaultrefcontext{0}{DBLP:journals/corr/SimonyanZ14a}{nty/global/}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{4}}
\global\@namedef{scr@dte@section@lastmaxnumwidth}{10.84047pt}
