Execution started: 
00:08:06.691101
Batch size: 40
Hard factor: 1.000000
Logit factor: 10.000000
Temperature: 2.000000
Soft factor: 10.000000
Intermediate layers in small model: [[3], []]
Intermediate layers in big model: [[5], []]
Weight decay: 0.000020
Number of epochs: 25
Epochs between LR decay: 10
Dataset used: CIFAR10
Files already downloaded and verified
Files already downloaded and verified
Big model initialized
Small model initialized
using SGD optimizer
LR is set to 0.004
Epoch 0/24, Training: Loss = 0.0500 Acc = 0.4795
Epoch 0/24, Testing: Loss = 0.1781 Acc = 0.6319
Epoch 1/24, Training: Loss = -0.0087 Acc = 0.7023
Epoch 1/24, Testing: Loss = 0.2499 Acc = 0.7280
Epoch 2/24, Training: Loss = -0.0400 Acc = 0.8173
Epoch 2/24, Testing: Loss = 0.3285 Acc = 0.7727
Epoch 3/24, Training: Loss = -0.0645 Acc = 0.9075
Epoch 3/24, Testing: Loss = 0.6393 Acc = 0.7677
Epoch 4/24, Training: Loss = -0.0772 Acc = 0.9538
Epoch 4/24, Testing: Loss = 0.8832 Acc = 0.7708
Epoch 5/24, Training: Loss = -0.0829 Acc = 0.9708
Epoch 5/24, Testing: Loss = 0.8984 Acc = 0.7820
Epoch 6/24, Training: Loss = -0.0863 Acc = 0.9798
Epoch 6/24, Testing: Loss = 1.0310 Acc = 0.7670
Epoch 7/24, Training: Loss = -0.0880 Acc = 0.9843
Epoch 7/24, Testing: Loss = 0.9591 Acc = 0.7702
Epoch 8/24, Training: Loss = -0.0900 Acc = 0.9894
Epoch 8/24, Testing: Loss = 1.2974 Acc = 0.7769
Epoch 9/24, Training: Loss = -0.0914 Acc = 0.9921
Epoch 9/24, Testing: Loss = 1.2698 Acc = 0.7825
LR is set to 0.0004
Epoch 10/24, Training: Loss = -0.0940 Acc = 0.9980
Epoch 10/24, Testing: Loss = 1.4431 Acc = 0.8014
Epoch 11/24, Training: Loss = -0.0946 Acc = 1.0000
Epoch 11/24, Testing: Loss = 1.7272 Acc = 0.8028
Epoch 12/24, Training: Loss = -0.0947 Acc = 1.0000
Epoch 12/24, Testing: Loss = 1.5197 Acc = 0.8026
Epoch 13/24, Training: Loss = -0.0947 Acc = 1.0000
Epoch 13/24, Testing: Loss = 1.8316 Acc = 0.8031
Epoch 14/24, Training: Loss = -0.0948 Acc = 1.0000
Epoch 14/24, Testing: Loss = 1.8506 Acc = 0.8032
Epoch 15/24, Training: Loss = -0.0948 Acc = 1.0000
Epoch 15/24, Testing: Loss = 1.4840 Acc = 0.8034
Epoch 16/24, Training: Loss = -0.0948 Acc = 1.0000
Epoch 16/24, Testing: Loss = 1.6941 Acc = 0.8033
Epoch 17/24, Training: Loss = -0.0949 Acc = 1.0000
Epoch 17/24, Testing: Loss = 1.6946 Acc = 0.8030
Epoch 18/24, Training: Loss = -0.0949 Acc = 1.0000
Epoch 18/24, Testing: Loss = 1.7954 Acc = 0.8028
Epoch 19/24, Training: Loss = -0.0949 Acc = 1.0000
Epoch 19/24, Testing: Loss = 1.7663 Acc = 0.8029
LR is set to 4.000000000000001e-05
Epoch 20/24, Training: Loss = -0.0950 Acc = 1.0000
Epoch 20/24, Testing: Loss = 1.8935 Acc = 0.8028
Epoch 21/24, Training: Loss = -0.0950 Acc = 1.0000
Epoch 21/24, Testing: Loss = 1.6686 Acc = 0.8028
Epoch 22/24, Training: Loss = -0.0950 Acc = 1.0000
Epoch 22/24, Testing: Loss = 1.4924 Acc = 0.8029
Epoch 23/24, Training: Loss = -0.0950 Acc = 1.0000
Epoch 23/24, Testing: Loss = 1.8326 Acc = 0.8030
Epoch 24/24, Training: Loss = -0.0950 Acc = 1.0000
Epoch 24/24, Testing: Loss = 1.7153 Acc = 0.8030
Training complete in 223m 21s
