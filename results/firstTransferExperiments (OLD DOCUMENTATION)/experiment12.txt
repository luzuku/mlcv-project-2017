Execution started: 
15:54:40.117326
Batch size: 40
Hard factor: 1.000000
Logit factor: 10.000000
Temperature: 2.000000
Soft factor: 60.000000
Intermediate layers in small model: [[0, 3, 6, 9, 12], [0]]
Intermediate layers in big model: [[0, 5, 10, 17, 24], [0]]
Weight decay: 0.000020
Number of epochs: 25
Epochs between LR decay: 10
Files already downloaded and verified
Files already downloaded and verified
Big model initialized
Small model initialized
using SGD optimizer
LR is set to 0.004
Epoch 0/24, Training: Loss = 1.9615 Acc = 0.4647
Epoch 0/24, Testing: Loss = 1.4490 Acc = 0.5124
Epoch 1/24, Training: Loss = 1.2841 Acc = 0.5142
Epoch 1/24, Testing: Loss = 1.3029 Acc = 0.4376
Epoch 2/24, Training: Loss = 1.1483 Acc = 0.5007
Epoch 2/24, Testing: Loss = 1.2684 Acc = 0.5174
Epoch 3/24, Training: Loss = 1.0841 Acc = 0.4847
Epoch 3/24, Testing: Loss = 1.1038 Acc = 0.3147
Epoch 4/24, Training: Loss = 1.0452 Acc = 0.4684
Epoch 4/24, Testing: Loss = 1.1489 Acc = 0.5518
Epoch 5/24, Training: Loss = 1.0258 Acc = 0.4435
Epoch 5/24, Testing: Loss = 1.1608 Acc = 0.3834
Epoch 6/24, Training: Loss = 1.0041 Acc = 0.4051
Epoch 6/24, Testing: Loss = 1.1119 Acc = 0.4427
Epoch 7/24, Training: Loss = 0.9927 Acc = 0.3888
Epoch 7/24, Testing: Loss = 1.0459 Acc = 0.2945
Epoch 8/24, Training: Loss = 0.9846 Acc = 0.3633
Epoch 8/24, Testing: Loss = 0.9982 Acc = 0.3906
Epoch 9/24, Training: Loss = 0.9829 Acc = 0.3549
Epoch 9/24, Testing: Loss = 1.1410 Acc = 0.3248
LR is set to 0.0004
Epoch 10/24, Training: Loss = 0.8901 Acc = 0.6215
Epoch 10/24, Testing: Loss = 1.1207 Acc = 0.7475
Epoch 11/24, Training: Loss = 0.8523 Acc = 0.8128
Epoch 11/24, Testing: Loss = 1.1153 Acc = 0.7919
Epoch 12/24, Training: Loss = 0.8462 Acc = 0.8049
Epoch 12/24, Testing: Loss = 1.1481 Acc = 0.7909
Epoch 13/24, Training: Loss = 0.8364 Acc = 0.8692
Epoch 13/24, Testing: Loss = 1.1901 Acc = 0.7834
Epoch 14/24, Training: Loss = 0.8293 Acc = 0.8911
Epoch 14/24, Testing: Loss = 1.1902 Acc = 0.7912
Epoch 15/24, Training: Loss = 0.8267 Acc = 0.8986
Epoch 15/24, Testing: Loss = 1.1652 Acc = 0.7670
Epoch 16/24, Training: Loss = 0.8234 Acc = 0.9100
Epoch 16/24, Testing: Loss = 1.2256 Acc = 0.7630
Epoch 17/24, Training: Loss = 0.8260 Acc = 0.9091
Epoch 17/24, Testing: Loss = 1.3440 Acc = 0.8017
Epoch 18/24, Training: Loss = 0.8241 Acc = 0.9163
Epoch 18/24, Testing: Loss = 1.3372 Acc = 0.7845
Epoch 19/24, Training: Loss = 0.8273 Acc = 0.9017
Epoch 19/24, Testing: Loss = 1.2224 Acc = 0.7983
LR is set to 4.000000000000001e-05
Epoch 20/24, Training: Loss = 0.8008 Acc = 0.9571
Epoch 20/24, Testing: Loss = 1.1790 Acc = 0.8186
Epoch 21/24, Training: Loss = 0.7929 Acc = 0.9658
Epoch 21/24, Testing: Loss = 1.1403 Acc = 0.8055
Epoch 22/24, Training: Loss = 0.7896 Acc = 0.9690
Epoch 22/24, Testing: Loss = 1.1730 Acc = 0.8119
Epoch 23/24, Training: Loss = 0.7875 Acc = 0.9700
Epoch 23/24, Testing: Loss = 1.1760 Acc = 0.7948
Epoch 24/24, Training: Loss = 0.7860 Acc = 0.9705
Epoch 24/24, Testing: Loss = 1.2186 Acc = 0.8051
Training complete in 241m 34s
